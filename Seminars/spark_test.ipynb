{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d297f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.5.4 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.4)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyspark==3.5.4) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da093b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32affd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# Проверка доступности портов\n",
    "\n",
    "\n",
    "def check_port(port):\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex(('127.0.0.1', port))\n",
    "    sock.close()\n",
    "    return result == 0\n",
    "\n",
    "\n",
    "print(\"Порт 7077 доступен:\", check_port(7077))\n",
    "print(\"Порт 7078 доступен:\", check_port(7078))\n",
    "\n",
    "# Запуск с диагностикой\n",
    "conf = SparkConf().setAppName(\"DiagApp\").setMaster(\"local[1]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "print(\"SparkContext создан успешно\")\n",
    "print(\"Версия Spark:\", sc.version)\n",
    "\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "print(\"RDD создан, количество партиций:\", rdd.getNumPartitions())\n",
    "\n",
    "result = rdd.mean()\n",
    "print(\"Результат:\", result)\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8426230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "\n",
    "# Самая простая конфигурация\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SimpleTest\") \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Быстрый тест\n",
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = sc.parallelize(data)\n",
    "print(\"Количество элементов:\", rdd.count())\n",
    "print(\"Среднее значение:\", rdd.mean())\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f693d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем порты: driver=49584, blockmanager=49585\n",
      "RDD создан успешно\n",
      "Среднее значение элементов в RDD: 3.0\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import random\n",
    "\n",
    "# Функция для поиска свободного порта\n",
    "\n",
    "\n",
    "def find_free_port():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind(('', 0))\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "\n",
    "# Используем случайные свободные порты\n",
    "driver_port = find_free_port()\n",
    "blockmanager_port = find_free_port()\n",
    "\n",
    "print(\n",
    "    f\"Используем порты: driver={driver_port}, blockmanager={blockmanager_port}\")\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"FixedApp\") \\\n",
    "    .setMaster(\"local[1]\") \\\n",
    "    .set(\"spark.driver.host\", \"localhost\") \\\n",
    "    .set(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .set(\"spark.driver.port\", str(driver_port)) \\\n",
    "    .set(\"spark.blockManager.port\", str(blockmanager_port)) \\\n",
    "    .set(\"spark.network.timeout\", \"300s\") \\\n",
    "    .set(\"spark.executor.heartbeatInterval\", \"30s\") \\\n",
    "    .set(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Тестируем\n",
    "try:\n",
    "    rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "    print(\"RDD создан успешно\")\n",
    "    mean_value = rdd.mean()\n",
    "    print(\"Среднее значение элементов в RDD:\", mean_value)\n",
    "except Exception as e:\n",
    "    print(\"Ошибка:\", e)\n",
    "finally:\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2549fc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение (вычислено вручную): 3.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Самый простой возможный вариант\n",
    "sc = SparkContext(\"local\", \"test\")\n",
    "\n",
    "# Вместо mean() вычисляем вручную\n",
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "# Вычисляем сумму и count отдельно\n",
    "total = rdd.sum()\n",
    "count = rdd.count()\n",
    "\n",
    "if count > 0:\n",
    "    mean_manual = total / count\n",
    "    print(f\"Среднее значение (вычислено вручную): {mean_manual}\")\n",
    "else:\n",
    "    print(\"RDD пуст\")\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e29e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a2b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18dabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedcd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
